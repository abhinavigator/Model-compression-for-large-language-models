{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport torch.nn.utils.prune as prune\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-05T07:51:40.252458Z","iopub.execute_input":"2024-05-05T07:51:40.252794Z","iopub.status.idle":"2024-05-05T07:51:47.294254Z","shell.execute_reply.started":"2024-05-05T07:51:40.252768Z","shell.execute_reply":"2024-05-05T07:51:47.293044Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-05 07:51:44.644752: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-05 07:51:44.644806: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-05 07:51:44.646347: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import Dataset\n\nclass SummarizationDataset(Dataset):\n    def __init__(self, tokenizer, file_path, max_length=512, use_percentage=10):\n        self.dataframe = pd.read_csv(file_path)\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n        # Sample a percentage of the data if use_percentage is less than 100\n        if use_percentage < 100:\n            self.dataframe = self.dataframe.sample(frac=use_percentage / 100.0, random_state=42).reset_index(drop=True)\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        article_text = row['article']\n        highlights_text = row['highlights']\n        \n        input_text = f\"summarize: {article_text}\"\n        source_encoding = self.tokenizer(\n            input_text,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        target_encoding = self.tokenizer(\n            highlights_text,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': source_encoding['input_ids'].squeeze(),\n            'attention_mask': source_encoding['attention_mask'].squeeze(),\n            'labels': target_encoding['input_ids'].squeeze()\n        }\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T07:51:47.296105Z","iopub.execute_input":"2024-05-05T07:51:47.296756Z","iopub.status.idle":"2024-05-05T07:51:47.307986Z","shell.execute_reply.started":"2024-05-05T07:51:47.296727Z","shell.execute_reply":"2024-05-05T07:51:47.306935Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# # Load tokenizer and model\n# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n# model = T5ForConditionalGeneration.from_pretrained('t5-small')","metadata":{"execution":{"iopub.status.busy":"2024-05-05T07:51:47.309525Z","iopub.execute_input":"2024-05-05T07:51:47.309919Z","iopub.status.idle":"2024-05-05T07:51:47.320969Z","shell.execute_reply.started":"2024-05-05T07:51:47.309880Z","shell.execute_reply":"2024-05-05T07:51:47.319776Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-05-05T07:51:47.322313Z","iopub.execute_input":"2024-05-05T07:51:47.322672Z","iopub.status.idle":"2024-05-05T07:51:47.328799Z","shell.execute_reply.started":"2024-05-05T07:51:47.322640Z","shell.execute_reply":"2024-05-05T07:51:47.327890Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class DistillationTrainer(Trainer):\n    def __init__(self, teacher_model, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.teacher_model = teacher_model\n        self.teacher_model.eval()  # Set the teacher model to evaluation mode\n        self.teacher_model.to(self.args.device)  # Move teacher model to the same device as the student model\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        # Generate outputs using the student model\n        outputs_student = model(**inputs)\n        # Generate outputs using the teacher model\n        with torch.no_grad():\n            inputs[\"decoder_input_ids\"] = inputs[\"labels\"]  # To ensure teacher uses correct inputs\n            outputs_teacher = self.teacher_model(**inputs)\n\n        # Compute distillation loss: Mean Squared Error (MSE) between logits\n        loss_fn = torch.nn.MSELoss()\n        distillation_loss = loss_fn(outputs_student.logits, outputs_teacher.logits)\n\n        # Optionally, add task-specific loss (e.g., cross-entropy), you might adjust the weights for these losses\n        if return_outputs:\n            return (distillation_loss, outputs_student)\n        return distillation_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-05T07:51:47.331393Z","iopub.execute_input":"2024-05-05T07:51:47.331689Z","iopub.status.idle":"2024-05-05T07:51:47.339779Z","shell.execute_reply.started":"2024-05-05T07:51:47.331663Z","shell.execute_reply":"2024-05-05T07:51:47.338908Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-05-05T07:51:47.340892Z","iopub.execute_input":"2024-05-05T07:51:47.341162Z","iopub.status.idle":"2024-05-05T07:51:47.351192Z","shell.execute_reply.started":"2024-05-05T07:51:47.341138Z","shell.execute_reply":"2024-05-05T07:51:47.350368Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Load models and tokenizer\nteacher_model = T5ForConditionalGeneration.from_pretrained('t5-base')\nstudent_model = T5ForConditionalGeneration.from_pretrained('t5-small')\ntokenizer = T5Tokenizer.from_pretrained('t5-small')","metadata":{"execution":{"iopub.status.busy":"2024-05-05T07:51:47.352159Z","iopub.execute_input":"2024-05-05T07:51:47.352425Z","iopub.status.idle":"2024-05-05T07:51:49.040560Z","shell.execute_reply.started":"2024-05-05T07:51:47.352403Z","shell.execute_reply":"2024-05-05T07:51:49.039628Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"path_of_csv_file= '/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv'","metadata":{"execution":{"iopub.status.busy":"2024-05-05T07:51:49.041768Z","iopub.execute_input":"2024-05-05T07:51:49.042060Z","iopub.status.idle":"2024-05-05T07:51:49.046231Z","shell.execute_reply.started":"2024-05-05T07:51:49.042034Z","shell.execute_reply":"2024-05-05T07:51:49.045268Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_data_path = '/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv'","metadata":{"execution":{"iopub.status.busy":"2024-05-05T07:51:49.047513Z","iopub.execute_input":"2024-05-05T07:51:49.047832Z","iopub.status.idle":"2024-05-05T07:51:49.055291Z","shell.execute_reply.started":"2024-05-05T07:51:49.047806Z","shell.execute_reply":"2024-05-05T07:51:49.054356Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ntrain_dataset = SummarizationDataset(tokenizer, path_of_csv_file,max_length =512, use_percentage = 10)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T07:51:49.056717Z","iopub.execute_input":"2024-05-05T07:51:49.057221Z","iopub.status.idle":"2024-05-05T07:52:02.868372Z","shell.execute_reply.started":"2024-05-05T07:51:49.057093Z","shell.execute_reply":"2024-05-05T07:52:02.867509Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"test_dataset = SummarizationDataset(tokenizer, test_data_path, max_length=512)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T07:52:03.058688Z","iopub.execute_input":"2024-05-05T07:52:03.059097Z","iopub.status.idle":"2024-05-05T07:52:03.587004Z","shell.execute_reply.started":"2024-05-05T07:52:03.059063Z","shell.execute_reply":"2024-05-05T07:52:03.585912Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a split ratio for training and validation\ntrain_size = int(0.9 * len(train_dataset))  # 90% for training\neval_size = len(train_dataset) - train_size  # 10% for evaluation","metadata":{"execution":{"iopub.status.busy":"2024-05-05T09:14:33.730843Z","iopub.execute_input":"2024-05-05T09:14:33.731262Z","iopub.status.idle":"2024-05-05T09:14:33.736191Z","shell.execute_reply.started":"2024-05-05T09:14:33.731228Z","shell.execute_reply":"2024-05-05T09:14:33.735251Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import random_split","metadata":{"execution":{"iopub.status.busy":"2024-05-05T09:14:59.919886Z","iopub.execute_input":"2024-05-05T09:14:59.920842Z","iopub.status.idle":"2024-05-05T09:14:59.925132Z","shell.execute_reply.started":"2024-05-05T09:14:59.920804Z","shell.execute_reply":"2024-05-05T09:14:59.924114Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Split the dataset\ntrain_subset, eval_subset = random_split(train_dataset, [train_size, eval_size])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T09:15:02.324024Z","iopub.execute_input":"2024-05-05T09:15:02.324393Z","iopub.status.idle":"2024-05-05T09:15:02.331602Z","shell.execute_reply.started":"2024-05-05T09:15:02.324362Z","shell.execute_reply":"2024-05-05T09:15:02.330558Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.init(mode=\"disabled\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T07:52:03.592797Z","iopub.execute_input":"2024-05-05T07:52:03.593110Z","iopub.status.idle":"2024-05-05T07:52:04.813602Z","shell.execute_reply.started":"2024-05-05T07:52:03.593082Z","shell.execute_reply":"2024-05-05T07:52:04.812694Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    fp16 = True,  # enable mixed precision it help speed up training\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    evaluation_strategy=\"epoch\",\n#     evaluation_strategy=\"no\",\n#     evaluation_strategy=\"steps\",\n    save_strategy=\"epoch\",\n#     load_best_model_at_end=True,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T09:15:39.886063Z","iopub.execute_input":"2024-05-05T09:15:39.886917Z","iopub.status.idle":"2024-05-05T09:15:39.920432Z","shell.execute_reply.started":"2024-05-05T09:15:39.886885Z","shell.execute_reply":"2024-05-05T09:15:39.919670Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from transformers import EarlyStoppingCallback","metadata":{"execution":{"iopub.status.busy":"2024-05-05T09:15:44.474806Z","iopub.execute_input":"2024-05-05T09:15:44.475715Z","iopub.status.idle":"2024-05-05T09:15:44.480077Z","shell.execute_reply.started":"2024-05-05T09:15:44.475679Z","shell.execute_reply":"2024-05-05T09:15:44.479017Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"trainer = DistillationTrainer(\n    teacher_model=teacher_model,\n    model=student_model,\n    args=training_args,\n    train_dataset=train_subset,\n    eval_dataset=eval_subset,\n    tokenizer=tokenizer\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T09:16:28.602566Z","iopub.execute_input":"2024-05-05T09:16:28.603655Z","iopub.status.idle":"2024-05-05T09:16:28.621814Z","shell.execute_reply.started":"2024-05-05T09:16:28.603615Z","shell.execute_reply":"2024-05-05T09:16:28.620863Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-05T09:16:31.417069Z","iopub.execute_input":"2024-05-05T09:16:31.417474Z","iopub.status.idle":"2024-05-05T10:33:39.060311Z","shell.execute_reply.started":"2024-05-05T09:16:31.417440Z","shell.execute_reply":"2024-05-05T10:33:39.059479Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3230' max='3230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3230/3230 1:17:05, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>7.122500</td>\n      <td>5.236245</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3230, training_loss=7.543378134334788, metrics={'train_runtime': 4627.296, 'train_samples_per_second': 5.584, 'train_steps_per_second': 0.698, 'total_flos': 3497096808235008.0, 'train_loss': 7.543378134334788, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"model = student_model","metadata":{"execution":{"iopub.status.busy":"2024-05-06T05:29:52.692709Z","iopub.execute_input":"2024-05-06T05:29:52.693052Z","iopub.status.idle":"2024-05-06T05:29:52.697461Z","shell.execute_reply.started":"2024-05-06T05:29:52.693026Z","shell.execute_reply":"2024-05-06T05:29:52.696561Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-05-06T05:39:48.151866Z","iopub.execute_input":"2024-05-06T05:39:48.152279Z","iopub.status.idle":"2024-05-06T05:40:00.319342Z","shell.execute_reply.started":"2024-05-06T05:39:48.152247Z","shell.execute_reply":"2024-05-06T05:40:00.318216Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-05-06T05:40:21.736788Z","iopub.execute_input":"2024-05-06T05:40:21.737231Z","iopub.status.idle":"2024-05-06T05:40:21.742437Z","shell.execute_reply.started":"2024-05-06T05:40:21.737166Z","shell.execute_reply":"2024-05-06T05:40:21.741452Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False,num_workers = 4)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T05:40:40.658015Z","iopub.execute_input":"2024-05-06T05:40:40.658678Z","iopub.status.idle":"2024-05-06T05:40:40.663316Z","shell.execute_reply.started":"2024-05-06T05:40:40.658644Z","shell.execute_reply":"2024-05-06T05:40:40.662310Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def compute_rouge_scores(model, dataloader):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n\n    predictions = []\n    references = []\n    rouge = load_metric('rouge', trust_remote_code=True)\n\n    for batch in dataloader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        with torch.no_grad():\n            outputs = model.generate(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                max_length=150,\n                num_beams=4,\n                length_penalty=2.0,\n                early_stopping=True\n            )\n\n        decoded_preds = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n        decoded_refs = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n\n        predictions.extend(decoded_preds)\n        references.extend(decoded_refs)\n\n    result = rouge.compute(predictions=predictions, references=references)\n    return result\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T05:40:52.527791Z","iopub.execute_input":"2024-05-06T05:40:52.528477Z","iopub.status.idle":"2024-05-06T05:40:52.537362Z","shell.execute_reply.started":"2024-05-06T05:40:52.528442Z","shell.execute_reply":"2024-05-06T05:40:52.536386Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# Now call the function\nrouge_scores = compute_rouge_scores(model, test_dataloader)\nprint(\"ROUGE Scores:\", rouge_scores)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T05:41:02.113551Z","iopub.execute_input":"2024-05-06T05:41:02.114576Z","iopub.status.idle":"2024-05-06T05:45:51.907198Z","shell.execute_reply.started":"2024-05-06T05:41:02.114540Z","shell.execute_reply":"2024-05-06T05:45:51.906077Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.37860150801855524, recall=0.3644438133539695, fmeasure=0.3605036498310606), mid=Score(precision=0.38729855112042405, recall=0.3728883465202554, fmeasure=0.36790665112815457), high=Score(precision=0.39663106258088404, recall=0.38131312970547937, fmeasure=0.3758778879222655)), 'rouge2': AggregateScore(low=Score(precision=0.1647436770638004, recall=0.15732297463493133, fmeasure=0.15600281403315705), mid=Score(precision=0.17298847894482808, recall=0.16545175618833638, fmeasure=0.16371361312004643), high=Score(precision=0.18202116402648422, recall=0.17317626596454702, fmeasure=0.17123023513487295)), 'rougeL': AggregateScore(low=Score(precision=0.2655018279037113, recall=0.2582814640040355, fmeasure=0.2538265806336129), mid=Score(precision=0.2733984387066724, recall=0.26584152146761664, fmeasure=0.26099577120687967), high=Score(precision=0.2817875474313138, recall=0.27304500160586664, fmeasure=0.26804751092522766)), 'rougeLsum': AggregateScore(low=Score(precision=0.26576670540189423, recall=0.258662497312861, fmeasure=0.2543661452440666), mid=Score(precision=0.2734916611963998, recall=0.26576634933681687, fmeasure=0.260890842629102), high=Score(precision=0.281704303326619, recall=0.27392196275534303, fmeasure=0.26847089933485063))}\n","output_type":"stream"}]},{"cell_type":"code","source":"def simplified_rouge_scores(rouge_results):\n    # Extract only mid F1 scores for ROUGE-1, ROUGE-2, and ROUGE-L\n    simplified_scores = {\n        'rouge1_fmeasure': rouge_results['rouge1'].mid.fmeasure,\n        'rouge2_fmeasure': rouge_results['rouge2'].mid.fmeasure,\n        'rougeL_fmeasure': rouge_results['rougeL'].mid.fmeasure\n    }\n    return simplified_scores\n\n# Assuming rouge_scores is the output from your previous compute_rouge_scores function\nsimplified_scores = simplified_rouge_scores(rouge_scores)\nprint(\"Simplified ROUGE Scores:\", simplified_scores)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T05:46:42.905702Z","iopub.execute_input":"2024-05-06T05:46:42.906067Z","iopub.status.idle":"2024-05-06T05:46:42.912764Z","shell.execute_reply.started":"2024-05-06T05:46:42.906035Z","shell.execute_reply":"2024-05-06T05:46:42.911794Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Simplified ROUGE Scores: {'rouge1_fmeasure': 0.36790665112815457, 'rouge2_fmeasure': 0.16371361312004643, 'rougeL_fmeasure': 0.26099577120687967}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:49:32.782856Z","iopub.execute_input":"2024-05-05T10:49:32.783259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:44:37.570717Z","iopub.execute_input":"2024-05-05T10:44:37.571701Z","iopub.status.idle":"2024-05-05T10:44:37.576034Z","shell.execute_reply.started":"2024-05-05T10:44:37.571662Z","shell.execute_reply":"2024-05-05T10:44:37.575050Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}