{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7669478,"sourceType":"datasetVersion","datasetId":4473093}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer\nfrom datasets import load_dataset ,load_metric\nimport torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AdamW\nimport pandas as pd\nfrom datasets import Dataset\nfrom datasets import load_dataset\nimport torch.nn.utils.prune as prune\nfrom transformers import TrainingArguments,Trainer\nimport sacrebleu","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-10T10:40:37.528460Z","iopub.execute_input":"2024-05-10T10:40:37.528842Z","iopub.status.idle":"2024-05-10T10:40:37.621193Z","shell.execute_reply.started":"2024-05-10T10:40:37.528813Z","shell.execute_reply":"2024-05-10T10:40:37.620345Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Load the tokenizer and model\nmodel_name = 'facebook/bart-base'\ntokenizer = BartTokenizer.from_pretrained(model_name)\nmodel = BartForConditionalGeneration.from_pretrained(model_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:14:33.665636Z","iopub.execute_input":"2024-05-10T10:14:33.666344Z","iopub.status.idle":"2024-05-10T10:14:37.242463Z","shell.execute_reply.started":"2024-05-10T10:14:33.666309Z","shell.execute_reply":"2024-05-10T10:14:37.241571Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load WMT 2014 English-German dataset\ndataset = load_dataset(\"wmt14\", \"de-en\",split = 'train')\ntest_dataset = load_dataset('wmt14',\"de-en\",split = 'test')\n\nval_dataset = load_dataset('wmt14',\"de-en\",split = 'validation')","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:14:37.243724Z","iopub.execute_input":"2024-05-10T10:14:37.244049Z","iopub.status.idle":"2024-05-10T10:15:26.856195Z","shell.execute_reply.started":"2024-05-10T10:14:37.244021Z","shell.execute_reply":"2024-05-10T10:15:26.855388Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"sampled_dataset = dataset.shuffle(seed=42).select(range(int(0.001 * len(dataset))))\ntest_sample_dataset = test_dataset.shuffle(seed = 42).select(range(int(0.01*len(test_dataset))))\n\nval_sample_dataset = val_dataset.shuffle(seed = 42).select(range(int(0.01*len(val_dataset))))","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:15:26.858653Z","iopub.execute_input":"2024-05-10T10:15:26.858956Z","iopub.status.idle":"2024-05-10T10:15:26.927688Z","shell.execute_reply.started":"2024-05-10T10:15:26.858929Z","shell.execute_reply":"2024-05-10T10:15:26.926719Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"sample = sampled_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:15:26.928985Z","iopub.execute_input":"2024-05-10T10:15:26.929628Z","iopub.status.idle":"2024-05-10T10:15:26.934460Z","shell.execute_reply.started":"2024-05-10T10:15:26.929594Z","shell.execute_reply":"2024-05-10T10:15:26.933478Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sample","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:15:26.935867Z","iopub.execute_input":"2024-05-10T10:15:26.936511Z","iopub.status.idle":"2024-05-10T10:15:26.949101Z","shell.execute_reply.started":"2024-05-10T10:15:26.936476Z","shell.execute_reply":"2024-05-10T10:15:26.948027Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'translation': {'de': 'In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.',\n  'en': \"On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\"}}"},"metadata":{}}]},{"cell_type":"code","source":"# Function to preprocess the data\ndef preprocess_function(examples):\n    # Extracting German and English texts from the 'translation' dictionary\n    inputs = [ex['de'] for ex in examples['translation']]\n    targets = [ex['en'] for ex in examples['translation']]\n    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding='max_length')\n\n    # Set up the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=1024, truncation=True, padding='max_length')\n\n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:15:26.950613Z","iopub.execute_input":"2024-05-10T10:15:26.950866Z","iopub.status.idle":"2024-05-10T10:15:26.958897Z","shell.execute_reply.started":"2024-05-10T10:15:26.950844Z","shell.execute_reply":"2024-05-10T10:15:26.958010Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Tokenize the dataset\ntokenized_datasets = sampled_dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)\ntest_tokenized_datasets = test_sample_dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)\n\nval_tokenized_datasets = val_sample_dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:15:26.960064Z","iopub.execute_input":"2024-05-10T10:15:26.960347Z","iopub.status.idle":"2024-05-10T10:15:33.794443Z","shell.execute_reply.started":"2024-05-10T10:15:26.960323Z","shell.execute_reply":"2024-05-10T10:15:33.793466Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/30 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4df4dff4b7d4dd58869ba16993d07c9"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ndef apply_pruning(model):\n    # Iterate over all modules and prune the linear layers found in the encoder and decoder\n    for name, module in model.named_modules():\n        if isinstance(module, torch.nn.Linear):\n            # Applying unstructured L1 pruning\n            prune.l1_unstructured(module, name='weight', amount=0.2)\n            # To make the pruning permanent, you might typically call prune.remove, but it is better to do it after training","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:15:33.795679Z","iopub.execute_input":"2024-05-10T10:15:33.795962Z","iopub.status.idle":"2024-05-10T10:15:33.801246Z","shell.execute_reply.started":"2024-05-10T10:15:33.795928Z","shell.execute_reply":"2024-05-10T10:15:33.800241Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Pruning before training\napply_pruning(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:15:33.802739Z","iopub.execute_input":"2024-05-10T10:15:33.803357Z","iopub.status.idle":"2024-05-10T10:15:39.430799Z","shell.execute_reply.started":"2024-05-10T10:15:33.803323Z","shell.execute_reply":"2024-05-10T10:15:39.429757Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy='epoch',\n    learning_rate=2e-5,\n    per_device_train_batch_size=2,\n    weight_decay=0.01,\n    save_total_limit=1,\n    num_train_epochs=1,\n#     predict_with_generate=True\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:15:39.432418Z","iopub.execute_input":"2024-05-10T10:15:39.432946Z","iopub.status.idle":"2024-05-10T10:15:39.539762Z","shell.execute_reply.started":"2024-05-10T10:15:39.432918Z","shell.execute_reply":"2024-05-10T10:15:39.538989Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets,\n    tokenizer=tokenizer,\n    eval_dataset=val_tokenized_datasets,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:16:11.384383Z","iopub.execute_input":"2024-05-10T10:16:11.384755Z","iopub.status.idle":"2024-05-10T10:16:12.099038Z","shell.execute_reply.started":"2024-05-10T10:16:11.384725Z","shell.execute_reply":"2024-05-10T10:16:12.098025Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nwandb.init(mode=\"disabled\")","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:16:15.652637Z","iopub.execute_input":"2024-05-10T10:16:15.653033Z","iopub.status.idle":"2024-05-10T10:16:16.585681Z","shell.execute_reply.started":"2024-05-10T10:16:15.652998Z","shell.execute_reply":"2024-05-10T10:16:16.584745Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"# Train the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:16:17.785814Z","iopub.execute_input":"2024-05-10T10:16:17.787024Z","iopub.status.idle":"2024-05-10T10:35:01.669835Z","shell.execute_reply.started":"2024-05-10T10:16:17.786985Z","shell.execute_reply":"2024-05-10T10:35:01.668944Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1127' max='1127' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1127/1127 18:40, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.110500</td>\n      <td>0.070609</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1127, training_loss=0.5368960675880141, metrics={'train_runtime': 1123.559, 'train_samples_per_second': 4.012, 'train_steps_per_second': 1.003, 'total_flos': 2748691953745920.0, 'train_loss': 0.5368960675880141, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"pip install sacrebleu\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:40:01.696324Z","iopub.execute_input":"2024-05-10T10:40:01.697232Z","iopub.status.idle":"2024-05-10T10:40:16.530247Z","shell.execute_reply.started":"2024-05-10T10:40:01.697198Z","shell.execute_reply":"2024-05-10T10:40:16.529047Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m832.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.12.25)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.2.1)\nDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-2.8.2 sacrebleu-2.4.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_translation(batch):\n    # Assuming batch['translation'] is a list of dictionaries\n    german_sentences = [item['de'] for item in batch['translation']]\n    english_sentences = [item['en'] for item in batch['translation']]\n\n    # Tokenize the German sentences\n    inputs = tokenizer(german_sentences, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n    inputs = {key: val.to(model.device) for key, val in inputs.items()}\n\n    # Generate outputs\n    outputs = model.generate(**inputs, max_length=512, num_beams=5)\n\n    # Decode the outputs to human-readable translations\n    translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    return {\"pred_translation\": translations}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:00:34.606029Z","iopub.execute_input":"2024-05-10T11:00:34.606785Z","iopub.status.idle":"2024-05-10T11:00:34.613588Z","shell.execute_reply.started":"2024-05-10T11:00:34.606750Z","shell.execute_reply":"2024-05-10T11:00:34.612622Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Apply translation generation function to the test dataset\nresults =test_dataset.map(generate_translation, batched=True, batch_size=16)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:00:35.232395Z","iopub.execute_input":"2024-05-10T11:00:35.233059Z","iopub.status.idle":"2024-05-10T11:14:08.000123Z","shell.execute_reply.started":"2024-05-10T11:00:35.233026Z","shell.execute_reply":"2024-05-10T11:14:07.999198Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3003 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e6f20b928be4a4ab173cc0f7a12d84a"}},"metadata":{}}]},{"cell_type":"code","source":"# Apply translation generation function to the test dataset\n# results =test_sample_dataset.map(generate_translation, batched=True, batch_size=16)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:50:29.752176Z","iopub.execute_input":"2024-05-10T10:50:29.753058Z","iopub.status.idle":"2024-05-10T10:50:46.476616Z","shell.execute_reply.started":"2024-05-10T10:50:29.753024Z","shell.execute_reply":"2024-05-10T10:50:46.475437Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/30 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58aed3a05711409ca9b6bd9c4fe153f6"}},"metadata":{}}]},{"cell_type":"code","source":"# Extract the translations and references\ntranslations = [result['pred_translation'] for result in results]\nreferences = [[ref['en']] for ref in results['translation']]  # Note references are expected as a list of lists\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:14:27.410596Z","iopub.execute_input":"2024-05-10T11:14:27.411591Z","iopub.status.idle":"2024-05-10T11:14:27.587772Z","shell.execute_reply.started":"2024-05-10T11:14:27.411553Z","shell.execute_reply":"2024-05-10T11:14:27.586957Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Compute BLEU score using sacrebleu\nbleu = sacrebleu.corpus_bleu(translations, references)\nprint(f\"BLEU Score: {bleu.score}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:14:32.141564Z","iopub.execute_input":"2024-05-10T11:14:32.141939Z","iopub.status.idle":"2024-05-10T11:14:32.753343Z","shell.execute_reply.started":"2024-05-10T11:14:32.141910Z","shell.execute_reply":"2024-05-10T11:14:32.752341Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"BLEU Score: 21.3643503198117\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def generate_translation(batch):\n#     # Print the batch structure to understand how the data is organized\n#     print(batch)\n#     return batch  # Return the batch as is for inspection\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:58:00.693924Z","iopub.execute_input":"2024-05-10T10:58:00.694660Z","iopub.status.idle":"2024-05-10T10:58:00.699222Z","shell.execute_reply.started":"2024-05-10T10:58:00.694627Z","shell.execute_reply":"2024-05-10T10:58:00.698163Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# test_sample_dataset.map(generate_translation, batched=True, batch_size=2)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:58:01.212326Z","iopub.execute_input":"2024-05-10T10:58:01.213242Z","iopub.status.idle":"2024-05-10T10:58:01.223378Z","shell.execute_reply.started":"2024-05-10T10:58:01.213208Z","shell.execute_reply":"2024-05-10T10:58:01.222334Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['translation'],\n    num_rows: 30\n})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}