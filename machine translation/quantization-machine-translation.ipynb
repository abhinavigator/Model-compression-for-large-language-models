{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install sacrebleu","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:11:48.122097Z","iopub.execute_input":"2024-05-15T06:11:48.122455Z","iopub.status.idle":"2024-05-15T06:12:00.810649Z","shell.execute_reply.started":"2024-05-15T06:11:48.122429Z","shell.execute_reply":"2024-05-15T06:12:00.809387Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sacrebleu in /opt/conda/lib/python3.10/site-packages (2.4.2)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2.8.2)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.12.25)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.2.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer\nfrom datasets import load_dataset ,load_metric\nimport torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AdamW\nimport pandas as pd\nfrom datasets import Dataset\nfrom datasets import load_dataset\nimport torch.nn.utils.prune as prune\nfrom transformers import TrainingArguments,Trainer\nimport sacrebleu","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:12:00.813277Z","iopub.execute_input":"2024-05-15T06:12:00.814129Z","iopub.status.idle":"2024-05-15T06:12:00.819975Z","shell.execute_reply.started":"2024-05-15T06:12:00.814095Z","shell.execute_reply":"2024-05-15T06:12:00.819009Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_name = 'facebook/bart-base'\ntokenizer = BartTokenizer.from_pretrained(model_name)\nmodel = BartForConditionalGeneration.from_pretrained('facebook/bart-base')","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:12:00.821820Z","iopub.execute_input":"2024-05-15T06:12:00.822258Z","iopub.status.idle":"2024-05-15T06:12:02.322593Z","shell.execute_reply.started":"2024-05-15T06:12:00.822222Z","shell.execute_reply":"2024-05-15T06:12:02.321622Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Load WMT 2014 English-German dataset\ndataset = load_dataset(\"wmt14\", \"de-en\",split = 'train')\ntest_dataset = load_dataset('wmt14',\"de-en\",split = 'test')\n\nval_dataset = load_dataset('wmt14',\"de-en\",split = 'validation')","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:12:02.323928Z","iopub.execute_input":"2024-05-15T06:12:02.324203Z","iopub.status.idle":"2024-05-15T06:12:37.069188Z","shell.execute_reply.started":"2024-05-15T06:12:02.324180Z","shell.execute_reply":"2024-05-15T06:12:37.068407Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31ebfc6007ec481289ccda1be268aace"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 280M/280M [00:01<00:00, 236MB/s]  \nDownloading data: 100%|██████████| 265M/265M [00:01<00:00, 220MB/s]  \nDownloading data: 100%|██████████| 273M/273M [00:01<00:00, 182MB/s]  \nDownloading data: 100%|██████████| 474k/474k [00:00<00:00, 1.50MB/s]\nDownloading data: 100%|██████████| 509k/509k [00:00<00:00, 1.02MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/4508785 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e518937298d44c9e826f53ec8086aa8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c25136d159e14a24afcc41c3f8a74a2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3003 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc3bf237c41b44f89a6dc68baa12002f"}},"metadata":{}}]},{"cell_type":"code","source":"sampled_dataset = dataset.shuffle(seed=42).select(range(int(0.001 * len(dataset))))\n# test_sample_dataset = test_dataset.shuffle(seed = 42).select(range(int(0.01*len(test_dataset))))\n\nval_sample_dataset = val_dataset.shuffle(seed = 42).select(range(int(0.01*len(val_dataset))))","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:12:37.071086Z","iopub.execute_input":"2024-05-15T06:12:37.071364Z","iopub.status.idle":"2024-05-15T06:12:41.792364Z","shell.execute_reply.started":"2024-05-15T06:12:37.071340Z","shell.execute_reply":"2024-05-15T06:12:41.791581Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Function to preprocess the data\ndef preprocess_function(examples):\n    # Extracting German and English texts from the 'translation' dictionary\n    inputs = [ex['de'] for ex in examples['translation']]\n    targets = [ex['en'] for ex in examples['translation']]\n    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding='max_length')\n\n    # Set up the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=1024, truncation=True, padding='max_length')\n\n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:12:41.793538Z","iopub.execute_input":"2024-05-15T06:12:41.793854Z","iopub.status.idle":"2024-05-15T06:12:41.800656Z","shell.execute_reply.started":"2024-05-15T06:12:41.793827Z","shell.execute_reply":"2024-05-15T06:12:41.799666Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Tokenize the dataset\ntokenized_datasets = sampled_dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)\n# test_tokenized_datasets = test_dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)\n\nval_tokenized_datasets = val_sample_dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:47:41.691254Z","iopub.execute_input":"2024-05-15T06:47:41.691620Z","iopub.status.idle":"2024-05-15T06:47:46.458807Z","shell.execute_reply.started":"2024-05-15T06:47:41.691594Z","shell.execute_reply":"2024-05-15T06:47:46.458013Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"#  Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy='epoch',\n    learning_rate=2e-5,\n    per_device_train_batch_size=2,\n    weight_decay=0.01,\n    save_total_limit=1,\n    num_train_epochs=1,\n#     predict_with_generate=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:13:23.155236Z","iopub.execute_input":"2024-05-15T06:13:23.156100Z","iopub.status.idle":"2024-05-15T06:13:23.278872Z","shell.execute_reply.started":"2024-05-15T06:13:23.156065Z","shell.execute_reply":"2024-05-15T06:13:23.278082Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets,\n    tokenizer=tokenizer,\n    eval_dataset=val_tokenized_datasets,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:13:25.389504Z","iopub.execute_input":"2024-05-15T06:13:25.389884Z","iopub.status.idle":"2024-05-15T06:13:26.548643Z","shell.execute_reply.started":"2024-05-15T06:13:25.389855Z","shell.execute_reply":"2024-05-15T06:13:26.547805Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nwandb.init(mode=\"disabled\")","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:13:45.990791Z","iopub.execute_input":"2024-05-15T06:13:45.991399Z","iopub.status.idle":"2024-05-15T06:13:46.572745Z","shell.execute_reply.started":"2024-05-15T06:13:45.991369Z","shell.execute_reply":"2024-05-15T06:13:46.571815Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"# Train the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:13:54.790118Z","iopub.execute_input":"2024-05-15T06:13:54.790885Z","iopub.status.idle":"2024-05-15T06:31:15.306428Z","shell.execute_reply.started":"2024-05-15T06:13:54.790852Z","shell.execute_reply":"2024-05-15T06:31:15.305467Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1127' max='1127' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1127/1127 17:15, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.106800</td>\n      <td>0.068782</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1127, training_loss=0.6717010030941087, metrics={'train_runtime': 1040.1878, 'train_samples_per_second': 4.334, 'train_steps_per_second': 1.083, 'total_flos': 2748691953745920.0, 'train_loss': 0.6717010030941087, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"model.eval()  # Set the model to evaluation mode\nquantized_model = torch.quantization.quantize_dynamic(\n    model, {torch.nn.Linear}, dtype=torch.qint8\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:32:29.325167Z","iopub.execute_input":"2024-05-15T06:32:29.325539Z","iopub.status.idle":"2024-05-15T06:32:30.589720Z","shell.execute_reply.started":"2024-05-15T06:32:29.325509Z","shell.execute_reply":"2024-05-15T06:32:30.588752Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# quantized_model.save_pretrained('./quantized_bart_model')","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:32:58.950615Z","iopub.execute_input":"2024-05-15T06:32:58.951564Z","iopub.status.idle":"2024-05-15T06:32:58.956048Z","shell.execute_reply.started":"2024-05-15T06:32:58.951529Z","shell.execute_reply":"2024-05-15T06:32:58.954802Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# test_dataset = dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:40:53.659982Z","iopub.execute_input":"2024-05-15T06:40:53.660353Z","iopub.status.idle":"2024-05-15T06:40:53.664572Z","shell.execute_reply.started":"2024-05-15T06:40:53.660327Z","shell.execute_reply":"2024-05-15T06:40:53.663633Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def generate_translation(batch):\n    # Assuming batch['translation'] is a list of dictionaries\n    german_sentences = [item['de'] for item in batch['translation']]\n    english_sentences = [item['en'] for item in batch['translation']]\n\n    # Tokenize the German sentences\n    inputs = tokenizer(german_sentences, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n    inputs = {key: val.to(model.device) for key, val in inputs.items()}\n\n    # Generate outputs\n    outputs = model.generate(**inputs, max_length=512, num_beams=5)\n\n    # Decode the outputs to human-readable translations\n    translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    return {\"pred_translation\": translations}","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:46:36.645253Z","iopub.execute_input":"2024-05-15T06:46:36.645634Z","iopub.status.idle":"2024-05-15T06:46:36.653027Z","shell.execute_reply.started":"2024-05-15T06:46:36.645604Z","shell.execute_reply":"2024-05-15T06:46:36.651947Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Apply translation generation function to the test dataset\nresults =test_dataset.map(generate_translation, batched=True, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:48:04.910304Z","iopub.execute_input":"2024-05-15T06:48:04.911165Z","iopub.status.idle":"2024-05-15T06:59:42.894713Z","shell.execute_reply.started":"2024-05-15T06:48:04.911130Z","shell.execute_reply":"2024-05-15T06:59:42.893815Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3003 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e90bed27bdbe43758a25cbe7c7da1499"}},"metadata":{}}]},{"cell_type":"code","source":"# Extract the translations and references\ntranslations = [result['pred_translation'] for result in results]\nreferences = [[ref['en']] for ref in results['translation']] ","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:59:42.896214Z","iopub.execute_input":"2024-05-15T06:59:42.896574Z","iopub.status.idle":"2024-05-15T06:59:43.081934Z","shell.execute_reply.started":"2024-05-15T06:59:42.896544Z","shell.execute_reply":"2024-05-15T06:59:43.081157Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute BLEU score using sacrebleu\nbleu = sacrebleu.corpus_bleu(translations, references)\nprint(f\"BLEU Score: {bleu.score}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-15T06:59:43.083059Z","iopub.execute_input":"2024-05-15T06:59:43.083354Z","iopub.status.idle":"2024-05-15T06:59:43.703439Z","shell.execute_reply.started":"2024-05-15T06:59:43.083328Z","shell.execute_reply":"2024-05-15T06:59:43.702460Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"BLEU Score: 20.556680845025987\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}