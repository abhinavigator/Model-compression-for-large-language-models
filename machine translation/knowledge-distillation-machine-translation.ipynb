{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer\nfrom datasets import load_dataset ,load_metric\nimport torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AdamW\nimport pandas as pd\nfrom datasets import Dataset\nfrom datasets import load_dataset\nimport torch.nn.utils.prune as prune\nfrom transformers import TrainingArguments,Trainer\nimport sacrebleu","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-13T06:55:11.216028Z","iopub.execute_input":"2024-05-13T06:55:11.216523Z","iopub.status.idle":"2024-05-13T06:55:15.071103Z","shell.execute_reply.started":"2024-05-13T06:55:11.216481Z","shell.execute_reply":"2024-05-13T06:55:15.070239Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-13 06:55:12.976746: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-13 06:55:12.976808: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-13 06:55:12.978496: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install sacrebleu","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:15.073277Z","iopub.execute_input":"2024-05-13T06:55:15.074421Z","iopub.status.idle":"2024-05-13T06:55:27.478236Z","shell.execute_reply.started":"2024-05-13T06:55:15.074390Z","shell.execute_reply":"2024-05-13T06:55:27.476833Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sacrebleu in /opt/conda/lib/python3.10/site-packages (2.4.2)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2.8.2)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.12.25)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.2.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the tokenizer and model\nteacher_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\nmodel_name = 'facebook/bart-base'\ntokenizer = BartTokenizer.from_pretrained(model_name)\nstudent_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:27.479830Z","iopub.execute_input":"2024-05-13T06:55:27.480196Z","iopub.status.idle":"2024-05-13T06:55:30.347010Z","shell.execute_reply.started":"2024-05-13T06:55:27.480162Z","shell.execute_reply":"2024-05-13T06:55:30.346075Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Ensure the teacher model does not track gradients\nfor param in teacher_model.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:30.348265Z","iopub.execute_input":"2024-05-13T06:55:30.348588Z","iopub.status.idle":"2024-05-13T06:55:30.354380Z","shell.execute_reply.started":"2024-05-13T06:55:30.348561Z","shell.execute_reply":"2024-05-13T06:55:30.353458Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"teacher_model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:30.357016Z","iopub.execute_input":"2024-05-13T06:55:30.357290Z","iopub.status.idle":"2024-05-13T06:55:30.372259Z","shell.execute_reply.started":"2024-05-13T06:55:30.357268Z","shell.execute_reply":"2024-05-13T06:55:30.371287Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"BartForConditionalGeneration(\n  (model): BartModel(\n    (shared): Embedding(50265, 768, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n      (layers): ModuleList(\n        (0-5): 6 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n      (layers): ModuleList(\n        (0-5): 6 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"\nteacher_model.cuda()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:30.373288Z","iopub.execute_input":"2024-05-13T06:55:30.373548Z","iopub.status.idle":"2024-05-13T06:55:30.752035Z","shell.execute_reply.started":"2024-05-13T06:55:30.373525Z","shell.execute_reply":"2024-05-13T06:55:30.751037Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"BartForConditionalGeneration(\n  (model): BartModel(\n    (shared): Embedding(50265, 768, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n      (layers): ModuleList(\n        (0-5): 6 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n      (layers): ModuleList(\n        (0-5): 6 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Load WMT 2014 English-German dataset\ndataset = load_dataset(\"wmt14\", \"de-en\",split = 'train')\ntest_dataset = load_dataset('wmt14',\"de-en\",split = 'test')\n\nval_dataset = load_dataset('wmt14',\"de-en\",split = 'validation')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:30.753483Z","iopub.execute_input":"2024-05-13T06:55:30.753891Z","iopub.status.idle":"2024-05-13T06:55:45.736884Z","shell.execute_reply.started":"2024-05-13T06:55:30.753855Z","shell.execute_reply":"2024-05-13T06:55:45.736047Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sampled_dataset = dataset.shuffle(seed=42).select(range(int(0.001 * len(dataset))))\ntest_sample_dataset = test_dataset.shuffle(seed = 42).select(range(int(0.01*len(test_dataset))))\n\nval_sample_dataset = val_dataset.shuffle(seed = 42).select(range(int(0.01*len(val_dataset))))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:45.738274Z","iopub.execute_input":"2024-05-13T06:55:45.738647Z","iopub.status.idle":"2024-05-13T06:55:45.812174Z","shell.execute_reply.started":"2024-05-13T06:55:45.738609Z","shell.execute_reply":"2024-05-13T06:55:45.811364Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Function to preprocess the data\ndef preprocess_function(examples):\n    # Extracting German and English texts from the 'translation' dictionary\n    inputs = [ex['de'] for ex in examples['translation']]\n    targets = [ex['en'] for ex in examples['translation']]\n    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding='max_length')\n\n    # Set up the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=1024, truncation=True, padding='max_length')\n\n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:45.813470Z","iopub.execute_input":"2024-05-13T06:55:45.813861Z","iopub.status.idle":"2024-05-13T06:55:45.820724Z","shell.execute_reply.started":"2024-05-13T06:55:45.813826Z","shell.execute_reply":"2024-05-13T06:55:45.819817Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Tokenize the dataset\ntokenized_datasets = sampled_dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)\ntest_tokenized_datasets = test_sample_dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)\n\nval_tokenized_datasets = val_sample_dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:45.821992Z","iopub.execute_input":"2024-05-13T06:55:45.822323Z","iopub.status.idle":"2024-05-13T06:55:52.711137Z","shell.execute_reply.started":"2024-05-13T06:55:45.822290Z","shell.execute_reply":"2024-05-13T06:55:52.710050Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# # Define the custom trainer\n# class DistillationTrainer(Trainer):\n#     def __init__(self, teacher_model, *args, **kwargs):\n#         super().__init__(*args, **kwargs)\n#         self.teacher_model = teacher_model\n\n#     def compute_loss(self, model, inputs, return_outputs=False):\n#         outputs_student = model(**inputs)\n#         with torch.no_grad():\n#             inputs[\"decoder_input_ids\"] = inputs[\"labels\"]\n#             outputs_teacher = self.teacher_model(**inputs)\n\n#         loss_fn = torch.nn.MSELoss()\n#         distillation_loss = loss_fn(outputs_student.logits, outputs_teacher.logits)\n\n#         if return_outputs:\n#             return (distillation_loss, outputs_student)\n#         return distillation_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:52.712482Z","iopub.execute_input":"2024-05-13T06:55:52.712806Z","iopub.status.idle":"2024-05-13T06:55:52.717358Z","shell.execute_reply.started":"2024-05-13T06:55:52.712780Z","shell.execute_reply":"2024-05-13T06:55:52.716457Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Define the custom trainer\nclass DistillationTrainer(Trainer):\n    def __init__(self, teacher_model, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.teacher_model = teacher_model\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        # Move all inputs to the correct device\n        inputs = {k: v.to(self.args.device) for k, v in inputs.items() if isinstance(v, torch.Tensor)}\n        \n        outputs_student = model(**inputs)\n        with torch.no_grad():\n            # The teacher also needs labels for the forward pass\n            inputs[\"decoder_input_ids\"] = inputs.get(\"labels\", inputs.get(\"decoder_input_ids\"))\n            outputs_teacher = self.teacher_model(**inputs)\n\n        loss_fn = torch.nn.MSELoss()\n        distillation_loss = loss_fn(outputs_student.logits, outputs_teacher.logits)\n\n        if return_outputs:\n            return (distillation_loss, outputs_student)\n        return distillation_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:52.718640Z","iopub.execute_input":"2024-05-13T06:55:52.718921Z","iopub.status.idle":"2024-05-13T06:55:52.733001Z","shell.execute_reply.started":"2024-05-13T06:55:52.718898Z","shell.execute_reply":"2024-05-13T06:55:52.732061Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.init(mode=\"disabled\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:52.734176Z","iopub.execute_input":"2024-05-13T06:55:52.734510Z","iopub.status.idle":"2024-05-13T06:55:54.190205Z","shell.execute_reply.started":"2024-05-13T06:55:52.734487Z","shell.execute_reply":"2024-05-13T06:55:54.189226Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"# Training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=1,\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=16,\n    per_device_eval_batch_size=2,\n    fp16=True,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:54.194485Z","iopub.execute_input":"2024-05-13T06:55:54.195272Z","iopub.status.idle":"2024-05-13T06:55:54.230989Z","shell.execute_reply.started":"2024-05-13T06:55:54.195236Z","shell.execute_reply":"2024-05-13T06:55:54.230234Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# training_args = TrainingArguments(\n#     output_dir='./results',\n#     num_train_epochs=1,\n#     per_device_train_batch_size=4,\n#     per_device_eval_batch_size=4,\n#     fp16 = True,  # enable mixed precision it help speed up training\n#     warmup_steps=500,\n#     weight_decay=0.01,\n#     logging_dir='./logs',\n#     logging_steps=10,\n#     evaluation_strategy=\"epoch\",\n# #     evaluation_strategy=\"no\",\n# #     evaluation_strategy=\"steps\",\n#     save_strategy=\"epoch\",\n# #     load_best_model_at_end=True,\n# )","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:54.231977Z","iopub.execute_input":"2024-05-13T06:55:54.232238Z","iopub.status.idle":"2024-05-13T06:55:54.237066Z","shell.execute_reply.started":"2024-05-13T06:55:54.232215Z","shell.execute_reply":"2024-05-13T06:55:54.236159Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Initialize and start the trainer\ntrainer = DistillationTrainer(\n    teacher_model=teacher_model,\n    model=student_model,\n    args=training_args,\n    train_dataset=tokenized_datasets,\n    eval_dataset=val_tokenized_datasets,\n    tokenizer=tokenizer\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:54.238143Z","iopub.execute_input":"2024-05-13T06:55:54.238433Z","iopub.status.idle":"2024-05-13T06:55:54.417494Z","shell.execute_reply.started":"2024-05-13T06:55:54.238378Z","shell.execute_reply":"2024-05-13T06:55:54.416603Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T06:55:54.418826Z","iopub.execute_input":"2024-05-13T06:55:54.419178Z","iopub.status.idle":"2024-05-13T07:20:17.526570Z","shell.execute_reply.started":"2024-05-13T06:55:54.419145Z","shell.execute_reply":"2024-05-13T07:20:17.525578Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [70/70 23:59, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>5.743519</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nThere were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=70, training_loss=8.821241106305804, metrics={'train_runtime': 1462.6909, 'train_samples_per_second': 3.082, 'train_steps_per_second': 0.048, 'total_flos': 2731619332915200.0, 'train_loss': 8.821241106305804, 'epoch': 0.99})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-13T07:20:17.528074Z","iopub.execute_input":"2024-05-13T07:20:17.528435Z","iopub.status.idle":"2024-05-13T07:20:17.533185Z","shell.execute_reply.started":"2024-05-13T07:20:17.528407Z","shell.execute_reply":"2024-05-13T07:20:17.532174Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def generate_translation(batch):\n    # Assuming batch['translation'] is a list of dictionaries\n    german_sentences = [item['de'] for item in batch['translation']]\n    english_sentences = [item['en'] for item in batch['translation']]\n\n    # Tokenize the German sentences\n    inputs = tokenizer(german_sentences, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n    inputs = {key: val.to(student_model.device) for key, val in inputs.items()}\n\n    # Generate outputs\n    outputs = student_model.generate(**inputs, max_length=512, num_beams=5)\n\n    # Decode the outputs to human-readable translations\n    translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    return {\"pred_translation\": translations}","metadata":{"execution":{"iopub.status.busy":"2024-05-13T07:23:37.924074Z","iopub.execute_input":"2024-05-13T07:23:37.924886Z","iopub.status.idle":"2024-05-13T07:23:37.931879Z","shell.execute_reply.started":"2024-05-13T07:23:37.924847Z","shell.execute_reply":"2024-05-13T07:23:37.930998Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"results =test_dataset.map(generate_translation, batched=True, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T07:23:40.490818Z","iopub.execute_input":"2024-05-13T07:23:40.491279Z","iopub.status.idle":"2024-05-13T07:43:16.436858Z","shell.execute_reply.started":"2024-05-13T07:23:40.491246Z","shell.execute_reply":"2024-05-13T07:43:16.435520Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3003 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a778ab00d384d72a092b468a6f79a03"}},"metadata":{}}]},{"cell_type":"code","source":"# Extract the translations and references\ntranslations = [result['pred_translation'] for result in results]\nreferences = [[ref['en']] for ref in results['translation']]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T07:43:33.399805Z","iopub.execute_input":"2024-05-13T07:43:33.400253Z","iopub.status.idle":"2024-05-13T07:43:33.594565Z","shell.execute_reply.started":"2024-05-13T07:43:33.400219Z","shell.execute_reply":"2024-05-13T07:43:33.593538Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Compute BLEU score using sacrebleu\nbleu = sacrebleu.corpus_bleu(translations, references)\nprint(f\"BLEU Score: {bleu.score}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T07:43:34.925052Z","iopub.execute_input":"2024-05-13T07:43:34.925552Z","iopub.status.idle":"2024-05-13T07:43:35.590360Z","shell.execute_reply.started":"2024-05-13T07:43:34.925511Z","shell.execute_reply":"2024-05-13T07:43:35.589372Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"BLEU Score: 7.223943354597204\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}